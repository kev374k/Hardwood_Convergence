{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range(1991, 2023)\n",
    "mvp_requests = \"https://www.basketball-reference.com/awards/awards_{}.html\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gets requests from basketball reference in order to determine who won MVP in the last ~30 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for year in years:\n",
    "#     page = requests.get(mvp_requests.format(year))\n",
    "    \n",
    "#     with open('mvps/{}.html'.format(year), 'w+') as file:\n",
    "#         file.write(page.text)\n",
    "\n",
    "# DO NOT RUN AGAIN - WILL CAUSE ERROR WITH BASKETBALL REFERENCE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From opening all csv files, locate only the MVP table and add the data from that table into a list of dataframes, as well as adding a 'Year' column to the data to ensure we know which year each MVP candidate is from. Use Beautiful Soup to get the data and convert it into readable html, and get rid of headers as well as find the necessary MVP information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "for year in years:\n",
    "    with open('files/mvps/{}.html'.format(year)) as f:\n",
    "        page = f.read()\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        soup.find('tr', class_ = 'over_header').decompose()\n",
    "        mvp_table = soup.find_all(id = 'mvp')\n",
    "        mvp = pd.read_html(str(mvp_table))[0]\n",
    "        mvp['Year'] = year\n",
    "        df.append(mvp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate the dataframes into one dataframe using pd.concat(), and then make it into a csv called 'mvps.csv' for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvps = pd.concat(df)\n",
    "mvps.to_csv('files/mvps.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to build a machine-learning model based on predicting an MVP, we have to find out the player stats and associate the MVP votes with how well each player did. The problem is that we need to find these stats and get more requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "driver = webdriver.Safari()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use selenium to automate all the stats, since basketball-reference uses JavaScript to load in their stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_url = 'https://www.basketball-reference.com/leagues/NBA_{}_per_game.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# for year in years:\n",
    "#     with open('files/full_player_stats/{}.html'.format(year), 'w+') as file:\n",
    "#         driver.get(stats_url.format(year))\n",
    "#         driver.execute_script('window.scrollTo(1,10000)')\n",
    "#         time.sleep(2)\n",
    "#         html = driver.page_source\n",
    "#         file.write(html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = []\n",
    "# for year in years:\n",
    "#     with open('files/full_player_stats/{}.html'.format(year)) as f:\n",
    "#         f = f.read()\n",
    "#         soup = BeautifulSoup(f, 'html.parser')\n",
    "#         soup.find('tr', class_ = 'thead').decompose()\n",
    "#         player_stats = soup.find_all(id = 'per_game_stats')\n",
    "#         stats = pd.read_html(str(player_stats))[0]\n",
    "#         stats['Year'] = year\n",
    "        \n",
    "#         df.append(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pd.concat(df)\n",
    "stats.to_csv('files/player_stats.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, since the MVP race is often biased towards players who are winning(and rightfully so), we want to include the team record in the data in order to let the model adjust for those who are winning more. In order to do so, we look up the historic data for the season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record_url = 'https://www.basketball-reference.com/leagues/NBA_{}_standings.html' \n",
    "# for year in years:\n",
    "#     data = requests.get(record_url.format(year))\n",
    "#     with open('files/team_records/{}.html'.format(year), 'w+') as file:\n",
    "#         file.write(data.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "stats_url = 'https://www.basketball-reference.com/leagues/NBA_{}_standings.html' \n",
    "for year in years:\n",
    "    with open('files/team_records/{}.html'.format(year), 'w+') as file:\n",
    "        driver.get(stats_url.format(year))\n",
    "        driver.execute_script('window.scrollTo(1,10000)')\n",
    "        time.sleep(2)\n",
    "        html = driver.page_source\n",
    "        file.write(html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "for year in years:\n",
    "    with open('files/team_records/{}.html'.format(year)) as f:\n",
    "        f = f.read()\n",
    "        soup = BeautifulSoup(f, 'html.parser')\n",
    "        soup.find('tr', class_ = 'thead').decompose()\n",
    "        soup.find('tr', class_ = 'over_header').decompose()\n",
    "        player_stats = soup.find_all(id = 'expanded_standings')\n",
    "        stats = pd.read_html(str(player_stats))[0]\n",
    "        stats['Year'] = year\n",
    "\n",
    "        df.append(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat(df)\n",
    "data.to_csv('team_record.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
